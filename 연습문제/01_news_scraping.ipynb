{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.daum.net/economy\n",
      "<class 'requests.models.Response'>\n",
      "200\n",
      "<class 'bs4.element.ResultSet'> 9\n",
      "https://v.daum.net/v/20250722210317765\n",
      "韓 반도체는 깨어날 줄 모르고 [AI 칩 전쟁…한국은 없다?]\n",
      "https://v.daum.net/v/20250722204242273\n",
      "소비쿠폰 쓰려다가 '화들짝'…\"여기서는 못써요\" 응답에 '당황'한 소비자\n",
      "https://v.daum.net/v/20250722202007801\n",
      "‘해수부 부산 시대’ 조선·해양플랜트까지 업무 넓혀야\n",
      "https://v.daum.net/v/20250722200357366\n",
      "[이슈대담] “2040년 석탄화력발전소 폐쇄…신재생 에너지 전환”\n",
      "https://v.daum.net/v/20250722190900992\n",
      "경제통상 외교수장들, 대거 미국행... 관세 타결·한미정상회담 열릴까\n",
      "https://v.daum.net/v/20250722185103483\n",
      "퇴근하면 시작된다...유통업계 다시 불붙은 '6시 쇼핑' 전쟁\n",
      "https://v.daum.net/v/20250722183143976\n",
      "“자율주행, 이동약자 지원하는 ‘공공성’에 초점 맞춰야”\n",
      "https://v.daum.net/v/20250722181057244\n",
      "꾸준히 강세 흐름 보이는 메이저 알트코인들 : 코리안 크립토 위클리 [INFCL 리서치]\n",
      "https://v.daum.net/v/20250722175548581\n",
      "세계시장 제패한 K뷰티·푸드…'첨단' 아니라며 R&D지원은 쥐꼬리\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 다음 경제 뉴스 URL\n",
    "url = 'https://news.daum.net/economy'\n",
    "\n",
    "# 요청 및 응답 확인\n",
    "res = requests.get(url)\n",
    "res.encoding = 'utf-8'  # 인코딩 지정\n",
    "\n",
    "print(url)\n",
    "print(type(res))           # <class 'requests.models.Response'>\n",
    "print(res.status_code)     # 200이면 성공\n",
    "\n",
    "# HTML 파싱\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# 뉴스 리스트 추출\n",
    "li_tags = soup.select('ul.list_newsheadline2 li')\n",
    "print(type(li_tags), len(li_tags))  # <class 'bs4.element.ResultSet'>, 뉴스 개수\n",
    "\n",
    "# 링크와 제목 출력\n",
    "for li in li_tags:\n",
    "    a_tag = li.find('a')\n",
    "    link = a_tag['href']\n",
    "    \n",
    "    strong_tag = li.select_one('div.cont_thumb strong.tit_txt')\n",
    "    title = strong_tag.text.strip() if strong_tag else '(제목 없음)'\n",
    "    \n",
    "    print(link)\n",
    "    print(title)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 섹션명과 URL 끝 경로 매핑\n",
    "section_dict = {\n",
    "    '기후/환경': 'climate',\n",
    "    '사회': 'society',\n",
    "    '경제': 'economy',\n",
    "    '정치': 'politics',\n",
    "    '국제': 'world',\n",
    "    '문화': 'culture',\n",
    "    '생활': 'life',\n",
    "    'IT/과학': 'tech',\n",
    "    '인물': 'people'\n",
    "}\n",
    "\n",
    "# 뉴스 출력 함수\n",
    "def print_news(section_name):\n",
    "    # 1. 섹션 영문 경로 추출\n",
    "    if section_name not in section_dict:\n",
    "        print(f\"[오류] '{section_name}' 섹션은 존재하지 않습니다.\")\n",
    "        return\n",
    "    \n",
    "    section_path = section_dict[section_name]\n",
    "    url = f'https://news.daum.net/{section_path}'\n",
    "    \n",
    "    print(f\"\\n======> {url} {section_name} 뉴스 <======\")\n",
    "\n",
    "    # 2. 웹 요청 및 파싱\n",
    "    res = requests.get(url)\n",
    "    res.encoding = 'utf-8'\n",
    "    if res.status_code != 200:\n",
    "        print(f\"[에러] 요청 실패: {res.status_code}\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # 3. 뉴스 리스트 선택자\n",
    "    li_tags = soup.select('ul.list_newsheadline2 li')\n",
    "\n",
    "    # 4. 결과 출력\n",
    "    for li in li_tags:\n",
    "        a_tag = li.find('a')\n",
    "        link = a_tag['href'] if a_tag else '(링크 없음)'\n",
    "        \n",
    "        strong_tag = li.select_one('div.cont_thumb strong.tit_txt')\n",
    "        title = strong_tag.text.strip() if strong_tag else '(제목 없음)'\n",
    "        \n",
    "        print(link)\n",
    "        print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======> https://news.daum.net/economy 경제 뉴스 <======\n",
      "https://v.daum.net/v/20250722210317765\n",
      "韓 반도체는 깨어날 줄 모르고 [AI 칩 전쟁…한국은 없다?]\n",
      "https://v.daum.net/v/20250722204242273\n",
      "소비쿠폰 쓰려다가 '화들짝'…\"여기서는 못써요\" 응답에 '당황'한 소비자\n",
      "https://v.daum.net/v/20250722202007801\n",
      "‘해수부 부산 시대’ 조선·해양플랜트까지 업무 넓혀야\n",
      "https://v.daum.net/v/20250722200357366\n",
      "[이슈대담] “2040년 석탄화력발전소 폐쇄…신재생 에너지 전환”\n",
      "https://v.daum.net/v/20250722190900992\n",
      "경제통상 외교수장들, 대거 미국행... 관세 타결·한미정상회담 열릴까\n",
      "https://v.daum.net/v/20250722185103483\n",
      "퇴근하면 시작된다...유통업계 다시 불붙은 '6시 쇼핑' 전쟁\n",
      "https://v.daum.net/v/20250722183143976\n",
      "“자율주행, 이동약자 지원하는 ‘공공성’에 초점 맞춰야”\n",
      "https://v.daum.net/v/20250722181057244\n",
      "꾸준히 강세 흐름 보이는 메이저 알트코인들 : 코리안 크립토 위클리 [INFCL 리서치]\n",
      "https://v.daum.net/v/20250722175548581\n",
      "세계시장 제패한 K뷰티·푸드…'첨단' 아니라며 R&D지원은 쥐꼬리\n",
      "\n",
      "======> https://news.daum.net/people 인물 뉴스 <======\n",
      "https://v.daum.net/v/20250722214300560\n",
      "[농촌 살리는 귀농스토리] ‘아버지 농법’ 걷어내고 ‘선진기술’로 일군 ‘대농의 꿈’\n",
      "https://v.daum.net/v/20250722192238426\n",
      "황규철 옥천군수 “옥천의 미래 위한 초심 잃지 않겠다”\n",
      "https://v.daum.net/v/20250722192212410\n",
      "“그 시절 떠오르니 즐겁구먼유”\n",
      "https://v.daum.net/v/20250722184640374\n",
      "[인터뷰…공감] “러브버그와 공존 방법 찾겠다” 박선재 국립생물자원관 연구관\n",
      "https://v.daum.net/v/20250722175908739\n",
      "[인터뷰] 홍덕기 부산체중·고 사이클팀 감독 “올해 상반기 상승세 이어나가 전국 최강팀 발돋움할 것”\n",
      "https://v.daum.net/v/20250722110743169\n",
      "[청년이 돌아왔다, 귀향시대] (20·끝) 이제는 귀향 아닌 정착\n",
      "https://v.daum.net/v/20250722060027468\n",
      "[예술가의 방] 도자공예가 편예린 | 전원생활\n",
      "https://v.daum.net/v/20250722050313918\n",
      "\"여행은 내 경계 확인하는 경험\"…휠체어 타고 세계 누빈 유튜버\n",
      "https://v.daum.net/v/20250722030327266\n",
      "“가상 K팝 아이돌, BTS도 못가본 경지 올라”\n",
      "https://v.daum.net/v/20250722043157507\n",
      "[가만한 당신] 아이의 열정으로 일식을 쫓은 \"아마추어\" NASA 과학자\n",
      "https://v.daum.net/v/20250721183651189\n",
      "고미술-현대미술 관통하는 ‘조형정신’ 읽어냈던 컬렉터\n",
      "https://v.daum.net/v/20250716050208639\n",
      "‘조수미를 픽업한 지휘자의 대명사’ 헤르베르트 폰 카라얀[신문에서 찾았다 오늘 별이 된 사람]\n",
      "https://v.daum.net/v/20250714184637316\n",
      "조작간첩 50년 만의 무죄 “동지들 곁에서 외롭지 않겠죠”\n",
      "https://v.daum.net/v/20250713193144618\n",
      "“박창희 교수, 50년대 재일동포 차별에 평생 민족 문제 파고들어”\n",
      "https://v.daum.net/v/20250722184640374\n",
      "[인터뷰…공감] “러브버그와 공존 방법 찾겠다” 박선재 국립생물자원관 연구관\n"
     ]
    }
   ],
   "source": [
    "print_news('경제')\n",
    "print_news('인물')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Nate 섹션 URL 매핑\n",
    "section_dict = {\n",
    "    '최신뉴스': 'n0100',\n",
    "    '정치': 'n0200',\n",
    "    '경제': 'n0300',\n",
    "    '사회': 'n0400',\n",
    "    '세계': 'n0500',\n",
    "    'IT/과학': 'n0600'\n",
    "}\n",
    "\n",
    "# 기본 도메인\n",
    "base_url = 'https://news.nate.com/recent?mid='\n",
    "image_base = 'https:'\n",
    "\n",
    "# 뉴스 출력 함수\n",
    "def print_nate_news(section_name):\n",
    "    # 1. 섹션 코드 확인\n",
    "    mid = section_dict.get(section_name)\n",
    "    if not mid:\n",
    "        print(f\"[오류] '{section_name}' 섹션은 존재하지 않습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 2. URL 생성 및 요청\n",
    "    url = base_url + mid\n",
    "    print(f'\\n======> {url} {section_name} 뉴스 <======')\n",
    "\n",
    "    headers = {\n",
    "        \"user-agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/138.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        news_items = soup.select('div.post')  # 뉴스 영역\n",
    "\n",
    "        print(f\"[총 {len(news_items)}개 뉴스]\")\n",
    "\n",
    "        for idx, item in enumerate(news_items, 1):\n",
    "            # 제목과 링크\n",
    "            a_tag = item.select_one('a.lt1')\n",
    "            if not a_tag:\n",
    "                continue\n",
    "            title = a_tag.text.strip()\n",
    "            link = a_tag['href']\n",
    "            full_link = urljoin(base_url, link)\n",
    "\n",
    "            # 이미지 처리\n",
    "            img_tag = item.select_one('span.thumb img')\n",
    "            if img_tag and img_tag.has_attr('src'):\n",
    "                img_src = img_tag['src'].strip()\n",
    "                img_url = urljoin(image_base, img_src)\n",
    "            else:\n",
    "                img_url = None\n",
    "\n",
    "            # 결과 출력\n",
    "            print(f'{idx}. {title}')\n",
    "            print(f'링크: {full_link}')\n",
    "            if img_url:\n",
    "                print(f'이미지: {img_url}')\n",
    "                display(Image(img_url))\n",
    "            else:\n",
    "                print('이미지 없음')\n",
    "    else:\n",
    "        print(f\"[Error] 응답 실패. 상태코드 = {res.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def download_one_episode(title, no, url):\n",
    "    # 요청 헤더\n",
    "    req_header = {\n",
    "        'referer': url,\n",
    "        \"user-agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/104.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    res = requests.get(url, headers=req_header)\n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        img_tags = soup.select(\"img[src*='IMAG01']\")\n",
    "\n",
    "        # 디렉토리 생성: img/제목/회차번호\n",
    "        base_dir = os.path.join(\"img\", title, str(no))\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "        for idx, img_tag in enumerate(img_tags, 1):\n",
    "            img_url = img_tag['src']\n",
    "            img_data = requests.get(img_url, headers=req_header).content\n",
    "\n",
    "            ext = os.path.splitext(img_url)[-1]\n",
    "            filename = f\"{idx:03d}{ext}\"\n",
    "            file_path = os.path.join(base_dir, filename)\n",
    "\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(img_data)\n",
    "                print(f\"✓ 저장됨: {file_path} ({len(img_data):,} bytes)\")\n",
    "    else:\n",
    "        print(f\"[Error] 요청 실패: {res.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
